{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1 HW\n",
    "\n",
    "\n",
    "1. This assignment is a group effort.\n",
    "2. Submission to be uploaded into your group repositories in the folder week1\n",
    "3. Deadline is 27th of April 5:00 PM.\n",
    "4. Please follow google's [python styleguide](https://google.github.io/styleguide/pyguide.html) for your code. Pay attention to the guidelines for naming convention, comments and main.\n",
    "5. Code will be checked for plagiarism. Compelling signs of a duplicated effort will lead to a rejection of submission and will attract a 100\\% grade penalty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the template provided as a starting point. Extend the classes as you see fit. Be careful to place new attributes and methods in the approriate class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "\n",
    "Extend the classes to include the following methods\n",
    "\n",
    "1. document_term_matrix - which returns a D by V array of frequency counts.\n",
    "2. tf_idf - returns a D by V array of tf-idf scores\n",
    "3. dict_rank - returns the top `n` documents based on a given dictionary and represenation of tokens (eg. doc-term matrix or tf-idf matrix)  \n",
    "\n",
    "Include subroutines as and when necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In Matthew's environment, a harmless exception is thrown from the following import.\n",
    "# Actually, it seems to be the first import, whatever it is.  Anyway, just ignore it.\n",
    "try:\n",
    "    from nltk.tokenize import wordpunct_tokenize\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "import codecs\n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import operator\n",
    "from nltk import PorterStemmer\n",
    "from math import log\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Document():    \n",
    "    \"\"\"\n",
    "    The Doc class represents a class of individual documents\n",
    "    \"\"\"    \n",
    "    def __init__(self, speech_year, speech_pres, speech_text):\n",
    "        self.year = speech_year\n",
    "        self.pres = speech_pres\n",
    "        self.text = speech_text.lower()\n",
    "        self.tokens = np.array(wordpunct_tokenize(self.text))\n",
    "    \n",
    "    def friendly_string(self):\n",
    "        \"\"\" \n",
    "        Description: generate a friendly string to describe the document\n",
    "        \"\"\"\n",
    "        return \"{0} {1} {2}\".format(self.year, self.pres, self.text[1:20])\n",
    "        \n",
    "    def token_clean(self,length):\n",
    "        \"\"\" \n",
    "        Description: strip out non-alpha tokens and tokens of length > 'length'\n",
    "        input: length: cut off length \n",
    "        \"\"\"\n",
    "        self.tokens = np.array([t for t in self.tokens if\n",
    "                                (t.isalpha() and len(t) > length)])\n",
    "\n",
    "    def stopword_remove(self, stopwords):\n",
    "        \"\"\"\n",
    "        Description: remove stopwords from tokens.\n",
    "        input: stopwords: a suitable list of stopwords\n",
    "        \"\"\"\n",
    "        self.tokens = np.array([t for t in self.tokens if t not in stopwords])\n",
    "\n",
    "    def stem(self):\n",
    "        \"\"\"\n",
    "        Description: stem tokens with Porter Stemmer.\n",
    "        \"\"\"\n",
    "        self.tokens = np.array([PorterStemmer().stem(t) for t in self.tokens])\n",
    "\n",
    "    def term_vector(self, corpus_token_list):\n",
    "        \"\"\"\n",
    "        Description: generate a term-vector for this document.  The result\n",
    "                     corresponds with a single row of the document-term-matrix\n",
    "                     of the corpus\n",
    "        input: corpus_token_list: a list of tokens from the corpus, a subset\n",
    "                                  of which will be found in this document.\n",
    "        \"\"\"\n",
    "        vector = [None] * len(corpus_token_list)\n",
    "        counter = Counter(self.tokens)\n",
    "        for i in range(len(corpus_token_list)):\n",
    "            count = counter[corpus_token_list[i]]\n",
    "            vector[i] = count\n",
    "\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Corpus():\n",
    "    \"\"\"\n",
    "    The Corpus class represents a document collection.\n",
    "    \"\"\"\n",
    "    def __init__(self, doc_data, stopword_file, clean_length):\n",
    "        \"\"\"\n",
    "        Notice that the __init__ method is invoked everytime an object of the\n",
    "        class is instantiated.\n",
    "        \"\"\"\n",
    "        # Initialise documents by invoking the appropriate class\n",
    "        self.docs = [Document(doc[0], doc[1], doc[2]) for doc in doc_data]         \n",
    "        self.N = len(self.docs)\n",
    "        self.clean_length = clean_length\n",
    "        \n",
    "        # Get a list of stopwords\n",
    "        self.create_stopwords(stopword_file, clean_length)\n",
    "        \n",
    "        # Stopword removal, token cleaning and stemming to docs\n",
    "        self.clean_docs(2)\n",
    "        \n",
    "        # Create vocabulary\n",
    "        self.corpus_tokens()\n",
    "        \n",
    "    def clean_docs(self, length):\n",
    "        \"\"\" \n",
    "        Applies stopword removal, token cleaning and stemming to docs.\n",
    "        \"\"\"\n",
    "        for doc in self.docs:\n",
    "            doc.token_clean(length)\n",
    "            doc.stopword_remove(self.stopwords)\n",
    "            doc.stem()        \n",
    "    \n",
    "    def create_stopwords(self, stopword_file, length):\n",
    "        \"\"\"\n",
    "        Description: parses a file of stopwords, removes words of length\n",
    "        'length' and  stems it.\n",
    "        input: length: cutoff length for words\n",
    "               stopword_file: stopwords file to parse\n",
    "        \"\"\"        \n",
    "        with codecs.open(stopword_file, 'r', 'utf-8') as f: raw = f.read()        \n",
    "        self.stopwords = (np.array([PorterStemmer().stem(word) \n",
    "                                    for word in list(raw.splitlines()) if len(word) > length]))\n",
    "             \n",
    "    def corpus_tokens(self):\n",
    "        \"\"\"\n",
    "        Description: create a set of all all tokens or in other words a\n",
    "        vocabulary\n",
    "        \"\"\"        \n",
    "        # Initialise an empty set\n",
    "        self.token_set = set()\n",
    "        for doc in self.docs:\n",
    "            self.token_set = self.token_set.union(doc.tokens) \n",
    "    \n",
    "    def document_term_matrix(self):\n",
    "        \"\"\"\n",
    "        Description: generate the document-term matrix for the corpus\n",
    "        \"\"\"        \n",
    "        result = []\n",
    "        for doc in self.docs:\n",
    "            vector = doc.term_vector(list(self.token_set))\n",
    "            result.append(vector)        \n",
    "        \n",
    "        return result\n",
    "\n",
    "    def tf_idf(self):\n",
    "        \"\"\"\n",
    "        Description: generate the TF-IDF matrix for this corpus\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate a copy of the document-term matrix to work with in this\n",
    "        # function and initialize other local variables.\n",
    "        dt_matrix = self.document_term_matrix()\n",
    "        tf_matrix = []\n",
    "        idf_matrix = []\n",
    "        tf_idf_matrix = []\n",
    "\n",
    "        # Build a term frequency matrix from the document term matrix.\n",
    "        # tf(d,v) = { 0 if x(d,v) = 0, 1 + log(x(d), v) otherwise }\n",
    "        for dt_doc_vector in dt_matrix:\n",
    "            tf_doc_vector = [(0 if x == 0 else 1 + log(x)) for x in dt_doc_vector]\n",
    "            tf_matrix.append(tf_doc_vector)\n",
    "\n",
    "        # Build a document frequency matrix for each term.\n",
    "        # Initialize with zeros.\n",
    "        df_vector = np.zeros(len(self.token_set))\n",
    "        for dt_doc_vector in dt_matrix:\n",
    "            # Increment the counters based on an indicator function which\n",
    "            # is 1 if there is at least one instance of the term in the doc.\n",
    "            df_vector = np.add(df_vector, [int(x > 0) for x in dt_doc_vector])\n",
    "\n",
    "        # Build an inverse document frequency vector.\n",
    "        idf_doc_vector = [log(len(self.docs) / x) for x in df_vector]\n",
    "\n",
    "        # Build the TF-IDF weighting matrix.\n",
    "        for tf_doc_vector in tf_matrix:\n",
    "            tf_idf_vector = np.multiply(tf_doc_vector, idf_doc_vector)\n",
    "            tf_idf_matrix.append(tf_idf_vector)\n",
    "\n",
    "        return tf_idf_matrix\n",
    "\n",
    "    def dict_rank(self, dictionary, use_tf_idf, n):        \n",
    "        \"\"\"\n",
    "        Description: rank the documents in this corpus against the provided\n",
    "        dictionary.  Return the top n documents.\n",
    "        input: dictionary: the dictionary against which to rank the documents\n",
    "               use_tf_idf: True if the TF-IDF matrix is to be used; False if\n",
    "                           the document-term matrix is to be used.\n",
    "               n: the number of top-ranked documents to return\n",
    "        \"\"\"\n",
    "        if (use_tf_idf):\n",
    "            dtm = self.tf_idf()\n",
    "        else:\n",
    "            dtm = self.document_term_matrix()\n",
    "            \n",
    "        # Get rid of words in the document term matrix not in the dictionary\n",
    "        dict_tokens_set = set(item for item in dictionary)\n",
    "        intersection = dict_tokens_set & self.token_set\n",
    "        vec_positions = [int(token in intersection) for token in self.token_set] \n",
    "\n",
    "        # Get the score of each document\n",
    "        sums = np.zeros(len(dtm))\n",
    "        for j in range(len(dtm)):\n",
    "            sums[j] = sum([a * b for a, b in zip(dtm[j], vec_positions)])\n",
    "\n",
    "        # Order them and return the n top documents\n",
    "        order = sorted(range(len(sums)), key = lambda k: sums[k], reverse=True)\n",
    "        ordered_doc_data_n = [None] * len(dtm)\n",
    "        ordered_sums = np.zeros(len(dtm))\n",
    "\n",
    "        counter = 0        \n",
    "        for num in order:\n",
    "            ordered_doc_data_n[counter] = self.docs[num]\n",
    "            ordered_sums[counter] = sums[num]\n",
    "            counter += 1\n",
    "\n",
    "        return zip(ordered_doc_data_n[0:n], ordered_sums[0:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_text(textraw, regex):\n",
    "    \"\"\"\n",
    "    Takes raw string and performs two operations:\n",
    "      1. Breaks text into a list of speech, president and speech\n",
    "      2. Breaks speech into paragraphs\n",
    "    \"\"\"\n",
    "    prs_yr_spch_reg = re.compile(regex, re.MULTILINE|re.DOTALL)\n",
    "    \n",
    "    # Each tuple contains the year, name of the president and the speech text\n",
    "    prs_yr_spch = prs_yr_spch_reg.findall(textraw)\n",
    "    \n",
    "    # Convert immutabe tuple to mutable list\n",
    "    prs_yr_spch = [list(tup) for tup in prs_yr_spch]\n",
    "    for i in range(len(prs_yr_spch)):\n",
    "        prs_yr_spch[i][2] = prs_yr_spch[i][2].replace('\\n', '')\n",
    "    \n",
    "    # Sort\n",
    "    prs_yr_spch.sort()\n",
    "    \n",
    "    return prs_yr_spch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = open('./../data/pres_speech/sou_all.txt', 'r').read()\n",
    "regex = '_(\\d{4}).*?_[a-zA-Z]+.*?_[a-zA-Z]+.*?_([a-zA-Z]+)_\\*+(\\\\n{2}.*?)\\\\n{3}'\n",
    "pres_speech_list = parse_text(text, regex)\n",
    "\n",
    "# Instantiate the corpus class\n",
    "corpus = Corpus(pres_speech_list, './../data/stopwords/stopwords.txt', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2\n",
    "\n",
    "Pick a dictionary (or dictionaries) of your choice from the Harvard IV set, the Loughran-McDonald set, or some other of your choosing that you think may be relevant for the data you collected. Then conduct the following exercise:\n",
    "1. Use the two methods above to score each document in your data.\n",
    "2. Explore whether the scores diﬀer according to the meta data ﬁelds you gathered: for example, do diﬀerent speakers/sources/etc tend to receive a higher score than others?\n",
    "3. Do the answers to the previous question depend on whether tf-idf weighting is applied or not? Why do you think there is (or is not) a diﬀerence in your answers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest ranked documents using DTM are:\n",
      "1980 Carter 10862.0\n",
      "1981 Carter 10790.0\n",
      "1946 Truman 8777.0\n",
      "1907 Roosevelt 7780.0\n",
      "1910 Taft 7743.0\n",
      "1912 Taft 7248.0\n",
      "1979 Carter 7091.0\n",
      "1905 Roosevelt 6980.0\n",
      "1974 Nixon 6976.0\n",
      "1906 Roosevelt 6820.0\n",
      "\n",
      "The highest ranked documents using TF-IDF are:\n",
      "1981 Carter 3126.28385887\n",
      "1980 Carter 2783.87538596\n",
      "1907 Roosevelt 2644.91021908\n",
      "1906 Roosevelt 2517.71438185\n",
      "1905 Roosevelt 2372.89968469\n",
      "1908 Roosevelt 2276.13355816\n",
      "1901 Roosevelt 2202.12924387\n",
      "1898 McKinley 2153.85100093\n",
      "1912 Taft 2150.15922904\n",
      "1910 Taft 2143.43236803\n"
     ]
    }
   ],
   "source": [
    "# Harvard IV set\n",
    "file_handler = './../data/dictionary/inquirerbasic2.csv'\n",
    "dictionary = np.loadtxt(open(file_handler, 'rb'), dtype = 'str',\n",
    "                        delimiter = ';', skiprows = 1, comments = None)\n",
    "our_dictionary = sorted(set(elem[0].rstrip('#01234256789').lower() for elem in dictionary))\n",
    "\n",
    "# We'll look at the top 10 documents.\n",
    "n = 10\n",
    "\n",
    "# Document term matrix\n",
    "scored_docs = corpus.dict_rank(our_dictionary, False, n)\n",
    "print \"The highest ranked documents using DTM are:\"\n",
    "for i in range(len(scored_docs)):\n",
    "    print \"{0} {1} {2}\".format(scored_docs[i][0].year, scored_docs[i][0].pres, scored_docs[i][1])\n",
    "print\n",
    "\n",
    "# TF-IDF\n",
    "scored_docs = corpus.dict_rank(our_dictionary, True, n)\n",
    "print \"The highest ranked documents using TF-IDF are:\"\n",
    "for i in range(len(scored_docs)):\n",
    "    print \"{0} {1} {2}\".format(scored_docs[i][0].year, scored_docs[i][0].pres, scored_docs[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores by president, from lowest to highest:\n",
      "\n",
      "     Washington ******* 249\n",
      "      Jefferson ******** 285\n",
      "        Madison ********** 327\n",
      "         Monroe *************** 480\n",
      "          Adams *************** 481\n",
      "         Wilson **************** 518\n",
      "           Ford ******************** 657\n",
      "         Hoover ********************* 673\n",
      "     Eisenhower ********************** 733\n",
      "         Taylor *********************** 757\n",
      "        Harding *********************** 760\n",
      "         Reagan ************************ 777\n",
      "        Lincoln ************************ 784\n",
      "        Johnson ************************ 792\n",
      "          Tyler ************************** 832\n",
      "           Bush ************************** 847\n",
      "          Nixon ************************** 863\n",
      "         Truman *************************** 874\n",
      "       Coolidge *************************** 885\n",
      "          Grant **************************** 924\n",
      "        Jackson ***************************** 935\n",
      "          Buren ****************************** 966\n",
      "        Kennedy ****************************** 983\n",
      "         Pierce ******************************** 1045\n",
      "       Fillmore ********************************* 1057\n",
      "          Hayes ********************************* 1067\n",
      "        Clinton ********************************** 1106\n",
      "          Obama ************************************ 1159\n",
      "      Roosevelt ************************************ 1162\n",
      "         Arthur ************************************* 1191\n",
      "       Buchanan *************************************** 1276\n",
      "           Polk ******************************************* 1380\n",
      "       Harrison ******************************************* 1387\n",
      "      Cleveland ********************************************** 1474\n",
      "         Carter ************************************************ 1537\n",
      "           Taft *********************************************************** 1889\n",
      "       McKinley *********************************************************** 1898\n"
     ]
    }
   ],
   "source": [
    "scored_docs = corpus.dict_rank(our_dictionary, True, len(corpus.docs))\n",
    "presidents = set([scored_doc[0].pres for scored_doc in scored_docs])\n",
    "president_dictionary = {}\n",
    "for president in presidents:\n",
    "    scores = [scored_doc[1] for scored_doc in scored_docs if scored_doc[0].pres == president]\n",
    "    president_dictionary[president] = sum(scores)/len(scores)\n",
    "\n",
    "print (\"Average scores by president, from lowest to highest:\")\n",
    "print\n",
    "for pres_score in sorted(president_dictionary.items(), key=operator.itemgetter(1)):\n",
    "    print \"{0} {1} {2}\".format(pres_score[0].rjust(15), '*' * int(pres_score[1]/32), int(pres_score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\n",
    "\n",
    "We will now do a sentiment analysis using the AFINN list of words. AFINN is a list of English words rated for valence with an integer between minus five (negative) and plus five (positive). The words have been manually labeled by Finn Årup Nielsen in 2009-2011. A positive valence score can be interpreted as the word conveying a postive emotion and vice versa. \n",
    "\n",
    "Load _AFINN-111.txt_ from ./data/AFINN. Inspect the contents of the file and write a function that converts it into a dictionary where the keys are words and values are the valence scores attributed to them. You may use the readme file for hints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example word \"limited\": -1\n",
      "Example word \"badly\": -3\n",
      "Example word \"fabulous\": 4\n",
      "Sentiment dictionary loaded with length 2477.\n"
     ]
    }
   ],
   "source": [
    "def load_sentiment_dictionary(path):\n",
    "    \"\"\"\n",
    "    description: load a sentiment dictionary\n",
    "    input: path: the path to the dictionary\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    with open(path, 'rb') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter='\\t')\n",
    "        for row in csv_reader:\n",
    "            d[row[0]] = int(row[1])        \n",
    "\n",
    "    return(d)\n",
    "\n",
    "# Load the dictionary\n",
    "sentiment_dictionary = load_sentiment_dictionary('../data/AFINN/AFINN-111.txt')\n",
    "\n",
    "# Inspect sentiment dictionary\n",
    "print 'Example word \"limited\":', sentiment_dictionary['limited']\n",
    "print 'Example word \"badly\":', sentiment_dictionary['badly']\n",
    "print 'Example word \"fabulous\":', sentiment_dictionary['fabulous']\n",
    "print \"Sentiment dictionary loaded with length {0}.\".format(len(sentiment_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\n",
    "Now, use the presedential speeches from last week's HW to calculate its sentiment score. Match every word against the dictionary and come up with a metric that captures the sentiment value. If a word is not present mark its score as 0. Write a function that takes in a list of word and returns their sentiment score. What is the score of the speech you have been assigned? Which year, president gave the least and most positive speech?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_words_from_file(path):\n",
    "    # Read the file content.\n",
    "    file_handle = open(path)\n",
    "    file_content = file_handle.read()\n",
    "    file_handle.close()\n",
    "\n",
    "    # Extract the content as JSON and get a copy of the speech text.\n",
    "    speech = json.loads(file_content)[2]\n",
    "    stripped_text = speech\n",
    "\n",
    "    # For each nonalphanumeric character, replace with a space.  This is\n",
    "    # safer than replacing with an empty string because some punctuation\n",
    "    # separates words without a space, i.e. '--'.\n",
    "    for char in ',.:;[]\"?$:-':\n",
    "        stripped_text = stripped_text.replace(char, ' ')\n",
    "\n",
    "    # Split the string into words.\n",
    "    word_list = stripped_text.split(' ')\n",
    "\n",
    "    # Because of the way the punctuation was replaced with spaces, there are\n",
    "    # instances of multiple adjacent spaces.  Therefore, empty strings appear\n",
    "    # in the word list.  Remove these.\n",
    "    word_list = [word.lower() for word in word_list if word != '']\n",
    "\n",
    "    return(word_list)\n",
    "\n",
    "def calculate_sentiment_for_speech(sentiment_dictionary, words):\n",
    "    word_count = 0\n",
    "    sentiment = 0\n",
    "    for word in words:\n",
    "        if sentiment_dictionary.has_key(word):\n",
    "            sentiment += sentiment_dictionary[word]\n",
    "            word_count += 1\n",
    "\n",
    "    return float(sentiment)/float(word_count), sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1977 Ford : sentiment = 0.768802228412 ; cumulative sentiment score = 276\n",
      "1967 Johnson : sentiment = 0.484955752212 ; cumulative sentiment score = 274\n",
      "1897 McKinley : sentiment = 0.261044176707 ; cumulative sentiment score = 195\n"
     ]
    }
   ],
   "source": [
    "def print_results(sentiment_dictionary, path, friendly_string):\n",
    "    words = load_words_from_file(path)\n",
    "    sentiment, cumul_sent_score = calculate_sentiment_for_speech(sentiment_dictionary, words)\n",
    "    display_str = \"{0} : sentiment = {1} ; cumulative sentiment score = {2}\"\n",
    "    print display_str.format(friendly_string, sentiment, cumul_sent_score)\n",
    "\n",
    "print_results(sentiment_dictionary,\n",
    "              \"../data/pres_speech/1977_Ford_Matthew.txt\",\n",
    "              \"1977 Ford\")\n",
    "print_results(sentiment_dictionary,\n",
    "              \"../data/pres_speech/1967_Johnson_Roger.txt\",\n",
    "              \"1967 Johnson\")\n",
    "print_results(sentiment_dictionary,\n",
    "              \"../data/pres_speech/1897_McKinley_miquel.txt\",\n",
    "              \"1897 McKinley\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is evident from the data above, of the three speeches we have analyzed, McKinley in 1897 had the lowest sentiment, while Ford in 1977 had the highest sentiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
